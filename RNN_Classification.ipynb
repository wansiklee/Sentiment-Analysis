{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "RNN_Classification.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqHp9MeJYk0S",
        "colab_type": "text"
      },
      "source": [
        "# RNN 분류 모델"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4tAMLfXYk0U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRoxg522Yk0X",
        "colab_type": "text"
      },
      "source": [
        "# 학습 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6l8cgvqYk0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_IN_PATH = '/.data_in/'\n",
        "DATA_OUT_PATH = '/.data_out/'\n",
        "\n",
        "TRAIN_INPUT_DATA = 'train_input.npy'\n",
        "TRAIN_LABEL_DATA = 'train_label.npy'\n",
        "DATA_CONFIGS = 'data_configs.json'\n",
        "\n",
        "input_data = np.load(open(DATA_IN_PATH + TRAIN_INPUT_DATA, 'rb'))\n",
        "label_data = np.load(open(DATA_IN_PATH + TRAIN_LABEL_DATA, 'rb'))\n",
        "\n",
        "prepro_configs = None\n",
        "\n",
        "with open(DATA_IN_PATH + DATA_CONFIGS, 'r') as f:\n",
        "    prepro_configs = json.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rr0Q4xB7Yk0a",
        "colab_type": "text"
      },
      "source": [
        "# 학습과 검증 데이터셋 분리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IOIsU3AYk0b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "TEST_SPLIT = 0.1\n",
        "RANDOM_SEED = 13371447\n",
        "\n",
        "train_input, test_input, train_label, test_label = train_test_split(input_data, label_data,\n",
        "                                                                    test_size=TEST_SPLIT, random_state=RANDOM_SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruMt2t2tYk0e",
        "colab_type": "text"
      },
      "source": [
        "# 데이터 입력 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4ZLnGf7Yk0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "EPOCHS = 3\n",
        "\n",
        "def mapping_fn(X, Y):\n",
        "    inputs, labels = {'x': X}, Y\n",
        "    return inputs, labels\n",
        "\n",
        "def train_input_fn():\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((train_input, train_label))\n",
        "    dataset = dataset.shuffle(buffer_size=1000)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.map(mapping_fn)\n",
        "    dataset = dataset.repeat(count=EPOCHS)\n",
        "    iterator = dataset.make_one_shot_iterator()\n",
        "    \n",
        "    return iterator.get_next()\n",
        "\n",
        "def eval_input_fn():\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((test_input, test_label))\n",
        "    dataset = dataset.map(mapping_fn)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    iterator = dataset.make_one_shot_iterator()\n",
        "    \n",
        "    return iterator.get_next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qxqtt3FaYk0h",
        "colab_type": "text"
      },
      "source": [
        "# 모델 정의, 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzJRAZifYk0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOCAB_SIZE = prepro_configs['vocab_size']+1\n",
        "\n",
        "WORD_EMBEDDING_DIM = 100\n",
        "HIDDEN_STATE_DIM = 150\n",
        "DENSE_FEATURE_DIM = 150\n",
        "\n",
        "learning_rate = 0.001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBgbHXoXYk0l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_fn(features, labels, mode):\n",
        "    TRAIN = mode == tf.estimator.ModeKeys.TRAIN\n",
        "    EVAL = mode == tf.estimator.ModeKeys.EVAL\n",
        "    PREDICT = mode == tf.estimator.ModeKeys.PREDICT\n",
        "    \n",
        "    embedding_layer = tf.keras.layers.Embedding(VOCAB_SIZE, WORD_EMBEDDING_DIM)(features['x'])\n",
        "    embedding_layer = tf.keras.layers.Dropout(0.2)(embedding_layer)\n",
        "    \n",
        "    rnn_layers = [tf.nn.rnn_cell.LSTMCell(size) for size in [HIDDEN_STATE_DIM, HIDDEN_STATE_DIM]]\n",
        "    multi_rnn_cell = tf.nn.rnn_cell.MultiRNNCell(rnn_layers)\n",
        "    outputs, state = tf.nn.dynamic_rnn(cell=multi_rnn_cell,\n",
        "                                       inputs=embedding_layer,\n",
        "                                       dtype=tf.float32)\n",
        "    \n",
        "    outputs = tf.keras.layers.Dropout(0.2)(outputs)\n",
        "    hidden_layer = tf.keras.layers.Dense(DENSE_FEATURE_DIM, activation=tf.nn.tanh)(outputs[:,-1,:])\n",
        "    hidden_layer = tf.keras.layers.Dropout(0.2)(hidden_layer)\n",
        "    logits = tf.keras.layers.Dense(1)(hidden_layer)\n",
        "    logits = tf.squeeze(logits, axis=-1)\n",
        "    \n",
        "    sigmoid_logits = tf.nn.sigmoid(logits)\n",
        "    \n",
        "    loss = tf.losses.sigmoid_cross_entropy(labels, logits)\n",
        "    \n",
        "    if PREDICT:\n",
        "        predictions = {'sentiment': sigmoid_logits}\n",
        "        return tf.estimator.EstimatorSpec(mode=mode,\n",
        "                                          predictions=predictions)\n",
        "    \n",
        "    if EVAL:\n",
        "        accuracy = tf.metrics.accuracy(labels, tf.round(sigmoid_logits))\n",
        "        eval_metric_ops = {'acc': accuracy}\n",
        "        return tf.estimator.EstimatorSpec(mode=mode,\n",
        "                                          loss=loss,\n",
        "                                          eval_metric_ops=eval_metric_ops)\n",
        "    \n",
        "    if TRAIN:\n",
        "        global_step = tf.train.get_global_step()\n",
        "        train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step)\n",
        "        return tf.estimator.EstimatorSpec(mode=mode,\n",
        "                                          train_op=train_op,\n",
        "                                          loss=loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xclE3wtjYk0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists(DATA_OUT_PATH):\n",
        "    os.makedirs(DATA_OUT_PATH)\n",
        "    \n",
        "est = tf.estimator.Estimator(model_fn, model_dir=DATA_OUT_PATH+'checkpoint/rnn')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQybYrCWYk0s",
        "colab_type": "code",
        "outputId": "9518de9b-5633-47e4-b83e-9c6ac7fad313",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        }
      },
      "source": [
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "\n",
        "est.train(train_input_fn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0806 13:14:19.667761 140526941017984 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0806 13:14:19.773999 140526941017984 deprecation.py:323] From <ipython-input-5-b0057d75b21a>:14: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
            "W0806 13:14:19.981736 140526941017984 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0806 13:14:20.029159 140526941017984 deprecation.py:323] From <ipython-input-9-03114845c4a2>:9: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "W0806 13:14:20.031386 140526941017984 deprecation.py:323] From <ipython-input-9-03114845c4a2>:10: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "W0806 13:14:20.033154 140526941017984 deprecation.py:323] From <ipython-input-9-03114845c4a2>:13: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "W0806 13:14:20.457011 140526941017984 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0806 13:14:20.474094 140526941017984 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0806 13:14:21.561495 140526941017984 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7fcea73e8080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcJo40Cgei7z",
        "colab_type": "code",
        "outputId": "b9cd346b-3a0b-4363-e804-ba40c6ed7697",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "est.evaluate(eval_input_fn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'acc': 0.8368, 'global_step': 4221, 'loss': 0.40145606}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}